from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# ========== CONFIGURATION ==========
CHROMA_DB_PATH = "vectordb"
MODEL_NAME = "intfloat/multilingual-e5-large"  # Model embedding

# ========== RETRIEVE FROM VECTORDB ==========
def retrieve_from_db(query, db_path, model_name, top_k=1):
    # T·∫£i embedding model
    embeddings = HuggingFaceEmbeddings(model_name=model_name)
    
    # T·∫£i VectorDB t·ª´ th∆∞ m·ª•c ƒë√£ l∆∞u
    db = Chroma(persist_directory=db_path, embedding_function=embeddings)
    
    # Truy xu·∫•t c√°c k·∫øt qu·∫£ g·∫ßn nh·∫•t
    results = db.similarity_search(query, k=top_k)
    return results

# ========== MAIN ==========
if __name__ == "__main__":
    # Nh·∫≠p prompt t·ª´ ng∆∞·ªùi d√πng
    query = "Pipeline Configuration"
    
    # Th·ª±c hi·ªán truy xu·∫•t
    print("‚ö° ƒêang truy xu·∫•t d·ªØ li·ªáu t·ª´ VectorDB...")
    results = retrieve_from_db(query, CHROMA_DB_PATH, MODEL_NAME)
    
    # In k·∫øt qu·∫£
    print("\nüí° K·∫øt qu·∫£ truy xu·∫•t:")
    for i, result in enumerate(results, start=1):
        # L·∫•y t√™n file t·ª´ metadata
        file_name = result.metadata.get('source', 'Kh√¥ng r√µ ngu·ªìn')
        print(f"\nüî∏ K·∫øt qu·∫£ {i} (S√°ch: {file_name}, N·ªôi dung: {result.page_content})")
